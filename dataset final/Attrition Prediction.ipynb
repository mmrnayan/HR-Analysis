{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85ef8162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee Columns: Index(['Employee ID', 'Full Name', 'Date of Birth', 'Gender',\n",
      "       'Education Level', 'Hire Date', 'Department', 'Job Title',\n",
      "       'Organization Level', 'Region', 'Country', 'Latitude', 'Longitude',\n",
      "       'Employment Status', 'Employment Type', 'Base Salary ($)',\n",
      "       'Times Promoted', 'Years at Company', 'Current Employment Status',\n",
      "       'Annual Leave Entitlement (days)', 'Ethnicity'],\n",
      "      dtype='object')\n",
      "Resigned Table Columns: Index(['Employee ID', 'Resigned Date', 'Resigned Type', 'Resigned Reason',\n",
      "       'Work Environment Feedback', 'Management/Team Experience Score',\n",
      "       'Level at Exit', 'Resignation Reason ID'],\n",
      "      dtype='object')\n",
      "Resignation Reason Columns: Index(['Resignation Reason ID', 'Reason Description'], dtype='object')\n",
      "Exit Interview Survey Columns: Index(['Employee ID', 'Exit Interview ID', 'Primary Resignation Reason',\n",
      "       'Work Environment Satisfaction Score', 'Support Received'],\n",
      "      dtype='object')\n",
      "Employee Feedback Survey Columns: Index(['Employee ID', 'Year', 'Performance Feedback ID', 'Goal Clarity',\n",
      "       'Support for Goals', 'Manager Feedback Effectiveness',\n",
      "       'Team Collaboration Score', 'Additional Support Needed',\n",
      "       'Career Growth Satisfaction', 'Overall Performance Rating'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "employee = pd.read_csv('employee.csv')\n",
    "resigned_table = pd.read_csv('resigned_table.csv')\n",
    "resignation_reason = pd.read_csv('resignation_reason.csv')\n",
    "exit_interview_survey = pd.read_csv('exit_interview_survey.csv')\n",
    "employee_feedback_survey = pd.read_csv('employee_feedback_survey.csv')\n",
    "\n",
    "# Check column names for each dataset\n",
    "print(\"Employee Columns:\", employee.columns)\n",
    "print(\"Resigned Table Columns:\", resigned_table.columns)\n",
    "print(\"Resignation Reason Columns:\", resignation_reason.columns)\n",
    "print(\"Exit Interview Survey Columns:\", exit_interview_survey.columns)\n",
    "print(\"Employee Feedback Survey Columns:\", employee_feedback_survey.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7713e4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data Preview:\n",
      "   Employee ID     Full Name Date of Birth  Gender Education Level  \\\n",
      "0         1001   Kyle Martin    1987-10-07  Female     Associate's   \n",
      "1         1001   Kyle Martin    1987-10-07  Female     Associate's   \n",
      "2         1001   Kyle Martin    1987-10-07  Female     Associate's   \n",
      "3         1002  Nicole Young    2002-06-03    Male     Associate's   \n",
      "4         1002  Nicole Young    2002-06-03    Male     Associate's   \n",
      "\n",
      "    Hire Date Department              Job Title Organization Level  \\\n",
      "0  2021-11-17         IT  IT Support Specialist              Entry   \n",
      "1  2021-11-17         IT  IT Support Specialist              Entry   \n",
      "2  2021-11-17         IT  IT Support Specialist              Entry   \n",
      "3  2020-08-13         IT      Software Engineer        Operational   \n",
      "4  2020-08-13         IT      Software Engineer        Operational   \n",
      "\n",
      "          Region  ... Support Received    Year  Performance Feedback ID  \\\n",
      "0           Asia  ...              NaN  2021.0                      1.0   \n",
      "1           Asia  ...              NaN  2022.0                      2.0   \n",
      "2           Asia  ...              NaN  2023.0                      3.0   \n",
      "3  North America  ...              NaN  2020.0                      4.0   \n",
      "4  North America  ...              NaN  2021.0                      5.0   \n",
      "\n",
      "  Goal Clarity Support for Goals  Manager Feedback Effectiveness  \\\n",
      "0           No                No                             2.0   \n",
      "1           No               Yes                             3.0   \n",
      "2          Yes                No                             2.0   \n",
      "3          Yes                No                             1.0   \n",
      "4           No               Yes                             3.0   \n",
      "\n",
      "   Team Collaboration Score              Additional Support Needed  \\\n",
      "0                       5.0                More training resources   \n",
      "1                       1.0       More career growth opportunities   \n",
      "2                       5.0  More team collaboration opportunities   \n",
      "3                       4.0  More team collaboration opportunities   \n",
      "4                       3.0             Improved work-life balance   \n",
      "\n",
      "  Career Growth Satisfaction  Overall Performance Rating  \n",
      "0                        Yes                         3.0  \n",
      "1                         No                         3.0  \n",
      "2                         No                         4.0  \n",
      "3                         No                         1.0  \n",
      "4                         No                         3.0  \n",
      "\n",
      "[5 rows x 42 columns]\n",
      "Merged Data Columns: Index(['Employee ID', 'Full Name', 'Date of Birth', 'Gender',\n",
      "       'Education Level', 'Hire Date', 'Department', 'Job Title',\n",
      "       'Organization Level', 'Region', 'Country', 'Latitude', 'Longitude',\n",
      "       'Employment Status', 'Employment Type', 'Base Salary ($)',\n",
      "       'Times Promoted', 'Years at Company', 'Current Employment Status',\n",
      "       'Annual Leave Entitlement (days)', 'Ethnicity', 'Resigned Date',\n",
      "       'Resigned Type', 'Resigned Reason', 'Work Environment Feedback',\n",
      "       'Management/Team Experience Score', 'Level at Exit',\n",
      "       'Resignation Reason ID', 'Reason Description', 'Exit Interview ID',\n",
      "       'Primary Resignation Reason', 'Work Environment Satisfaction Score',\n",
      "       'Support Received', 'Year', 'Performance Feedback ID', 'Goal Clarity',\n",
      "       'Support for Goals', 'Manager Feedback Effectiveness',\n",
      "       'Team Collaboration Score', 'Additional Support Needed',\n",
      "       'Career Growth Satisfaction', 'Overall Performance Rating'],\n",
      "      dtype='object')\n",
      "Null Values per Column:\n",
      "Employee ID                               0\n",
      "Full Name                                 0\n",
      "Date of Birth                             0\n",
      "Gender                                    0\n",
      "Education Level                           0\n",
      "Hire Date                                 0\n",
      "Department                                0\n",
      "Job Title                                 0\n",
      "Organization Level                        0\n",
      "Region                                    0\n",
      "Country                                   0\n",
      "Latitude                                  0\n",
      "Longitude                                 0\n",
      "Employment Status                         0\n",
      "Employment Type                           0\n",
      "Base Salary ($)                           0\n",
      "Times Promoted                            0\n",
      "Years at Company                          0\n",
      "Current Employment Status                 0\n",
      "Annual Leave Entitlement (days)           0\n",
      "Ethnicity                                 0\n",
      "Resigned Date                          6220\n",
      "Resigned Type                          6220\n",
      "Resigned Reason                        6220\n",
      "Work Environment Feedback              6220\n",
      "Management/Team Experience Score       6220\n",
      "Level at Exit                          6220\n",
      "Resignation Reason ID                  6220\n",
      "Reason Description                     6220\n",
      "Exit Interview ID                      6220\n",
      "Primary Resignation Reason             6220\n",
      "Work Environment Satisfaction Score    6220\n",
      "Support Received                       6220\n",
      "Year                                     68\n",
      "Performance Feedback ID                  68\n",
      "Goal Clarity                             68\n",
      "Support for Goals                        68\n",
      "Manager Feedback Effectiveness           68\n",
      "Team Collaboration Score                 68\n",
      "Additional Support Needed                68\n",
      "Career Growth Satisfaction               68\n",
      "Overall Performance Rating               68\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Merge Resigned Table with Resignation Reason\n",
    "resigned_table = resigned_table.merge(\n",
    "    resignation_reason,\n",
    "    on='Resignation Reason ID',\n",
    "    how='left'\n",
    ")\n",
    "# Merge datasets on Employee ID\n",
    "merged_data = (\n",
    "    employee\n",
    "    .merge(resigned_table, on='Employee ID', how='left')\n",
    "    .merge(exit_interview_survey, on='Employee ID', how='left')\n",
    "    .merge(employee_feedback_survey, on='Employee ID', how='left')\n",
    ")\n",
    "\n",
    "# Preview merged data\n",
    "print(\"Merged Data Preview:\")\n",
    "print(merged_data.head())\n",
    "# Check merged data structure\n",
    "print(\"Merged Data Columns:\", merged_data.columns)\n",
    "print(\"Null Values per Column:\")\n",
    "print(merged_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a556ff67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in Merged Data After Adding 'Age' and 'Attrition':\n",
      "Index(['Employee ID', 'Full Name', 'Date of Birth', 'Gender',\n",
      "       'Education Level', 'Hire Date', 'Department', 'Job Title',\n",
      "       'Organization Level', 'Region', 'Country', 'Latitude', 'Longitude',\n",
      "       'Employment Status', 'Employment Type', 'Base Salary ($)',\n",
      "       'Times Promoted', 'Years at Company', 'Current Employment Status',\n",
      "       'Annual Leave Entitlement (days)', 'Ethnicity', 'Resigned Date',\n",
      "       'Resigned Type', 'Resigned Reason', 'Work Environment Feedback',\n",
      "       'Management/Team Experience Score', 'Level at Exit',\n",
      "       'Resignation Reason ID', 'Reason Description', 'Exit Interview ID',\n",
      "       'Primary Resignation Reason', 'Work Environment Satisfaction Score',\n",
      "       'Support Received', 'Year', 'Performance Feedback ID', 'Goal Clarity',\n",
      "       'Support for Goals', 'Manager Feedback Effectiveness',\n",
      "       'Team Collaboration Score', 'Additional Support Needed',\n",
      "       'Career Growth Satisfaction', 'Overall Performance Rating', 'Attrition',\n",
      "       'Age'],\n",
      "      dtype='object')\n",
      "Model Data Preview:\n",
      "   Age  Gender Education Level  Years at Company  Base Salary ($) Department  \\\n",
      "0   37  Female     Associate's                 1         75020.35         IT   \n",
      "1   37  Female     Associate's                 1         75020.35         IT   \n",
      "2   37  Female     Associate's                 1         75020.35         IT   \n",
      "3   22    Male     Associate's                 3        142825.60         IT   \n",
      "4   22    Male     Associate's                 3        142825.60         IT   \n",
      "\n",
      "               Job Title Organization Level Career Growth Satisfaction  \\\n",
      "0  IT Support Specialist              Entry                        Yes   \n",
      "1  IT Support Specialist              Entry                         No   \n",
      "2  IT Support Specialist              Entry                         No   \n",
      "3      Software Engineer        Operational                         No   \n",
      "4      Software Engineer        Operational                         No   \n",
      "\n",
      "   Manager Feedback Effectiveness  Team Collaboration Score  Attrition  \n",
      "0                             2.0                       5.0          0  \n",
      "1                             3.0                       1.0          0  \n",
      "2                             2.0                       5.0          0  \n",
      "3                             1.0                       4.0          0  \n",
      "4                             3.0                       3.0          0  \n",
      "Null Values in Model Data:\n",
      "Age                                0\n",
      "Gender                             0\n",
      "Education Level                    0\n",
      "Years at Company                   0\n",
      "Base Salary ($)                    0\n",
      "Department                         0\n",
      "Job Title                          0\n",
      "Organization Level                 0\n",
      "Career Growth Satisfaction        68\n",
      "Manager Feedback Effectiveness    68\n",
      "Team Collaboration Score          68\n",
      "Attrition                          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Calculate Age (ensure Date of Birth exists and is properly formatted)\n",
    "if 'Date of Birth' in merged_data.columns:\n",
    "    merged_data['Age'] = (\n",
    "        pd.to_datetime('today') - pd.to_datetime(merged_data['Date of Birth'])\n",
    "    ).dt.days // 365\n",
    "else:\n",
    "    print(\"Error: 'Date of Birth' column not found.\")\n",
    "\n",
    "# Define Attrition Column\n",
    "# Attrition = 1 if 'Resigned Date' is not null, else 0\n",
    "merged_data['Attrition'] = merged_data['Resigned Date'].notnull().astype(int)\n",
    "\n",
    "# Verify new columns\n",
    "print(\"Columns in Merged Data After Adding 'Age' and 'Attrition':\")\n",
    "print(merged_data.columns)\n",
    "\n",
    "# Select Features\n",
    "features = [\n",
    "    'Age', 'Gender', 'Education Level', 'Years at Company', 'Base Salary ($)',\n",
    "    'Department', 'Job Title', 'Organization Level', 'Career Growth Satisfaction',\n",
    "    'Manager Feedback Effectiveness', 'Team Collaboration Score'\n",
    "]\n",
    "\n",
    "# Subset the dataset for modeling\n",
    "model_data = merged_data[features + ['Attrition']]\n",
    "\n",
    "# Check the prepared dataset\n",
    "print(\"Model Data Preview:\")\n",
    "print(model_data.head())\n",
    "print(\"Null Values in Model Data:\")\n",
    "print(model_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fb1bf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values After Imputation:\n",
      "Age                               0\n",
      "Gender                            0\n",
      "Education Level                   0\n",
      "Years at Company                  0\n",
      "Base Salary ($)                   0\n",
      "Department                        0\n",
      "Job Title                         0\n",
      "Organization Level                0\n",
      "Career Growth Satisfaction        0\n",
      "Manager Feedback Effectiveness    0\n",
      "Team Collaboration Score          0\n",
      "Attrition                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "model_data['Career Growth Satisfaction'].fillna(\n",
    "    model_data['Career Growth Satisfaction'].mode()[0], inplace=True\n",
    ")\n",
    "model_data['Manager Feedback Effectiveness'].fillna(\n",
    "    model_data['Manager Feedback Effectiveness'].median(), inplace=True\n",
    ")\n",
    "model_data['Team Collaboration Score'].fillna(\n",
    "    model_data['Team Collaboration Score'].median(), inplace=True\n",
    ")\n",
    "\n",
    "# Verify that missing values are resolved\n",
    "print(\"Missing Values After Imputation:\")\n",
    "print(model_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c79776f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded and Scaled Data Preview:\n",
      "        Age  Gender  Education Level  Years at Company  Base Salary ($)  \\\n",
      "0 -0.336058       0                0         -1.552737         0.070499   \n",
      "1 -0.336058       0                0         -1.552737         0.070499   \n",
      "2 -0.336058       0                0         -1.552737         0.070499   \n",
      "3 -1.430761       1                0         -0.843911         2.867593   \n",
      "4 -1.430761       1                0         -0.843911         2.867593   \n",
      "\n",
      "   Department  Job Title  Organization Level  Career Growth Satisfaction  \\\n",
      "0           2          7                   0                           1   \n",
      "1           2          7                   0                           0   \n",
      "2           2          7                   0                           0   \n",
      "3           2         15                   2                           0   \n",
      "4           2         15                   2                           0   \n",
      "\n",
      "   Manager Feedback Effectiveness  Team Collaboration Score  Attrition  \n",
      "0                       -0.703825                  1.414996          0  \n",
      "1                        0.006769                 -1.418109          0  \n",
      "2                       -0.703825                  1.414996          0  \n",
      "3                       -1.414419                  0.706719          0  \n",
      "4                        0.006769                 -0.001557          0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Initialize encoders and scaler\n",
    "label_encoder = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Categorical columns to encode\n",
    "categorical_columns = ['Gender', 'Education Level', 'Department', 'Job Title', 'Organization Level', 'Career Growth Satisfaction']\n",
    "for col in categorical_columns:\n",
    "    model_data[col] = label_encoder.fit_transform(model_data[col])\n",
    "\n",
    "# Numerical columns to scale\n",
    "numerical_columns = ['Age', 'Years at Company', 'Base Salary ($)', 'Manager Feedback Effectiveness', 'Team Collaboration Score']\n",
    "model_data[numerical_columns] = scaler.fit_transform(model_data[numerical_columns])\n",
    "\n",
    "# Verify encoding and scaling\n",
    "print(\"Encoded and Scaled Data Preview:\")\n",
    "print(model_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ae0d0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Class Distribution:\n",
      "Attrition\n",
      "0    0.911522\n",
      "1    0.088478\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Testing Set Class Distribution:\n",
      "Attrition\n",
      "0    0.911355\n",
      "1    0.088645\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features and target\n",
    "X = model_data.drop(columns=['Attrition'])\n",
    "y = model_data['Attrition']\n",
    "\n",
    "# Split the dataset (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Check the distribution of the target in train and test sets\n",
    "print(\"Training Set Class Distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"\\nTesting Set Class Distribution:\")\n",
    "print(y_test.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5a2be35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1244    0]\n",
      " [  88   33]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "No Attrition       0.93      1.00      0.97      1244\n",
      "   Attrition       1.00      0.27      0.43       121\n",
      "\n",
      "    accuracy                           0.94      1365\n",
      "   macro avg       0.97      0.64      0.70      1365\n",
      "weighted avg       0.94      0.94      0.92      1365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the Random Forest model with class weights\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Attrition', 'Attrition']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01400efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Class Distribution after SMOTE:\n",
      "Attrition\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Columns to encode\n",
    "binary_columns = ['Gender']\n",
    "categorical_columns = ['Education Level', 'Department', 'Job Title', 'Organization Level', 'Career Growth Satisfaction', 'Manager Feedback Effectiveness', 'Team Collaboration Score']\n",
    "\n",
    "# Step 1: Encode categorical variables (binary with LabelEncoder, multi-category with OneHotEncoder)\n",
    "label_encoder = LabelEncoder()\n",
    "X['Gender'] = label_encoder.fit_transform(X['Gender'])\n",
    "\n",
    "# One-hot encode multi-category variables\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Step 2: Apply SMOTE\n",
    "y = merged_data['Attrition']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Verify the distribution after SMOTE\n",
    "print(f\"Training Set Class Distribution after SMOTE:\\n{y_resampled.value_counts(normalize=True)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7d0293d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1242    6]\n",
      " [  84   33]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      1248\n",
      "           1       0.85      0.28      0.42       117\n",
      "\n",
      "    accuracy                           0.93      1365\n",
      "   macro avg       0.89      0.64      0.69      1365\n",
      "weighted avg       0.93      0.93      0.92      1365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08a4a0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Confusion Matrix:\n",
      "[[1216   32]\n",
      " [ 104   13]]\n",
      "\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95      1248\n",
      "           1       0.29      0.11      0.16       117\n",
      "\n",
      "    accuracy                           0.90      1365\n",
      "   macro avg       0.61      0.54      0.55      1365\n",
      "weighted avg       0.87      0.90      0.88      1365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Train a Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Gradient Boosting Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_gb))\n",
    "\n",
    "print(\"\\nGradient Boosting Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8b54a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best parameters for Gradient Boosting: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Random Forest Confusion Matrix:\n",
      "[[1244    4]\n",
      " [  86   31]]\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      1248\n",
      "           1       0.89      0.26      0.41       117\n",
      "\n",
      "    accuracy                           0.93      1365\n",
      "   macro avg       0.91      0.63      0.69      1365\n",
      "weighted avg       0.93      0.93      0.92      1365\n",
      "\n",
      "Gradient Boosting Confusion Matrix:\n",
      "[[1241    7]\n",
      " [  53   64]]\n",
      "\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      1248\n",
      "           1       0.90      0.55      0.68       117\n",
      "\n",
      "    accuracy                           0.96      1365\n",
      "   macro avg       0.93      0.77      0.83      1365\n",
      "weighted avg       0.95      0.96      0.95      1365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Step 1: Adjust class weights for imbalanced classes\n",
    "rf_model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Step 2: Hyperparameter Tuning using GridSearchCV for RandomForest and Gradient Boosting\n",
    "# Define parameter grids for both models\n",
    "\n",
    "# Random Forest hyperparameters grid\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "}\n",
    "\n",
    "# Gradient Boosting hyperparameters grid\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5],\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for Random Forest\n",
    "rf_grid_search = GridSearchCV(rf_model, rf_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "rf_grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Perform GridSearchCV for Gradient Boosting\n",
    "gb_grid_search = GridSearchCV(gb_model, gb_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "gb_grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Best parameters found for Random Forest\n",
    "print(\"Best parameters for Random Forest:\", rf_grid_search.best_params_)\n",
    "\n",
    "# Best parameters found for Gradient Boosting\n",
    "print(\"Best parameters for Gradient Boosting:\", gb_grid_search.best_params_)\n",
    "\n",
    "# Step 3: Evaluate the models with the best parameters\n",
    "\n",
    "# Train the Random Forest model with best parameters\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "best_rf_model.fit(X_resampled, y_resampled)\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Train the Gradient Boosting model with best parameters\n",
    "best_gb_model = gb_grid_search.best_estimator_\n",
    "best_gb_model.fit(X_resampled, y_resampled)\n",
    "y_pred_gb = best_gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest performance\n",
    "print(\"Random Forest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "print(\"\\nRandom Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Evaluate Gradient Boosting performance\n",
    "print(\"Gradient Boosting Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_gb))\n",
    "\n",
    "print(\"\\nGradient Boosting Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d681bbb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This GradientBoostingClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Predict probabilities on the test set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m gb_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Extract the probability for the 'Attrition' class (class 1)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m attrition_probabilities \u001b[38;5;241m=\u001b[39m y_pred_proba[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:1666\u001b[0m, in \u001b[0;36mGradientBoostingClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1645\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   1646\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict class probabilities for X.\u001b[39;00m\n\u001b[0;32m   1647\u001b[0m \n\u001b[0;32m   1648\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1664\u001b[0m \u001b[38;5;124;03m        If the ``loss`` does not support probabilities.\u001b[39;00m\n\u001b[0;32m   1665\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1666\u001b[0m     raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[0;32m   1667\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss\u001b[38;5;241m.\u001b[39mpredict_proba(raw_predictions)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:1567\u001b[0m, in \u001b[0;36mGradientBoostingClassifier.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the decision function of ``X``.\u001b[39;00m\n\u001b[0;32m   1547\u001b[0m \n\u001b[0;32m   1548\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;124;03m    array of shape (n_samples,).\u001b[39;00m\n\u001b[0;32m   1563\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1564\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1565\u001b[0m     X, dtype\u001b[38;5;241m=\u001b[39mDTYPE, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m )\n\u001b[1;32m-> 1567\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_predict(X)\n\u001b[0;32m   1568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raw_predictions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m raw_predictions\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:961\u001b[0m, in \u001b[0;36mBaseGradientBoosting._raw_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raw_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    960\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the sum of the trees raw predictions (+ init estimator).\"\"\"\u001b[39;00m\n\u001b[1;32m--> 961\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    962\u001b[0m     raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_predict_init(X)\n\u001b[0;32m    963\u001b[0m     predict_stages(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_, X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate, raw_predictions)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1622\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This GradientBoostingClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# Predict probabilities on the test set\n",
    "y_pred_proba = gb_model.predict_proba(X_test)\n",
    "\n",
    "# Extract the probability for the 'Attrition' class (class 1)\n",
    "attrition_probabilities = y_pred_proba[:, 1]\n",
    "\n",
    "# Add these probabilities to the test set for further analysis\n",
    "test_results = X_test.copy()\n",
    "test_results['Actual Attrition'] = y_test\n",
    "test_results['Predicted Attrition Probability'] = attrition_probabilities\n",
    "\n",
    "# Display a sample of the results\n",
    "print(test_results[['Actual Attrition', 'Predicted Attrition Probability']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f72e400d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual Attrition  Predicted Attrition Probability\n",
      "101                  0                         0.141420\n",
      "2666                 0                         0.238370\n",
      "3838                 0                         0.284382\n",
      "2388                 0                         0.141948\n",
      "5438                 0                         0.268925\n",
      "\n",
      "Gradient Boosting Confusion Matrix:\n",
      "[[1216   32]\n",
      " [ 104   13]]\n",
      "\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95      1248\n",
      "           1       0.29      0.11      0.16       117\n",
      "\n",
      "    accuracy                           0.90      1365\n",
      "   macro avg       0.61      0.54      0.55      1365\n",
      "weighted avg       0.87      0.90      0.88      1365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'merged_data' contains your employee data, and 'X' and 'y' are the features and target variables respectively\n",
    "\n",
    "# Columns to encode\n",
    "binary_columns = ['Gender']\n",
    "categorical_columns = ['Education Level', 'Department', 'Job Title', 'Organization Level', \n",
    "                       'Career Growth Satisfaction', 'Manager Feedback Effectiveness', 'Team Collaboration Score']\n",
    "\n",
    "# Encode binary columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "X['Gender'] = label_encoder.fit_transform(X['Gender'])\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Define target variable (y)\n",
    "y = merged_data['Attrition']  # Assuming 'Attrition' is the target column indicating if the employee resigned or not\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to handle class imbalance (since attrition is likely imbalanced)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Fit the Gradient Boosting model on the resampled data\n",
    "gb_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "y_pred_proba = gb_model.predict_proba(X_test)\n",
    "\n",
    "# Extract the probability for the 'Attrition' class (class 1), i.e., resignation risk probability\n",
    "attrition_probabilities = y_pred_proba[:, 1]  # The probability for class 1 (resignation)\n",
    "\n",
    "# Add the probabilities to the test set for further analysis\n",
    "test_results = X_test.copy()\n",
    "test_results['Actual Attrition'] = y_test\n",
    "test_results['Predicted Attrition Probability'] = attrition_probabilities\n",
    "\n",
    "# Display a sample of the results (First few rows of actual vs predicted probabilities)\n",
    "print(test_results[['Actual Attrition', 'Predicted Attrition Probability']].head())\n",
    "\n",
    "# Confusion Matrix and Classification Report to evaluate model performance\n",
    "print(\"\\nGradient Boosting Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, gb_model.predict(X_test)))\n",
    "\n",
    "print(\"\\nGradient Boosting Classification Report:\")\n",
    "print(classification_report(y_test, gb_model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a73791e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual Attrition  Predicted Attrition Probability\n",
      "101                  0                         0.149227\n",
      "2666                 0                         0.292158\n",
      "3838                 0                         0.150576\n",
      "2388                 0                         0.144274\n",
      "5438                 0                         0.318445\n",
      "Gradient Boosting Confusion Matrix:\n",
      "[[1218   30]\n",
      " [ 104   13]]\n",
      "\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      1248\n",
      "           1       0.30      0.11      0.16       117\n",
      "\n",
      "    accuracy                           0.90      1365\n",
      "   macro avg       0.61      0.54      0.56      1365\n",
      "weighted avg       0.87      0.90      0.88      1365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "\n",
    "# Let's assume we have the following columns in your dataset\n",
    "# Age, Years at Company, Job Satisfaction, and other columns.\n",
    "\n",
    "# 1. Interaction terms between Age and Years at Company\n",
    "X['Age_Years_Interaction'] = X['Age'] * X['Years at Company']\n",
    "\n",
    "# 2. Polynomial features for Age and Years at Company (degree 2)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "age_years_poly = poly.fit_transform(X[['Age', 'Years at Company']])\n",
    "\n",
    "# Convert the polynomial features into DataFrame\n",
    "poly_features_df = pd.DataFrame(age_years_poly, columns=poly.get_feature_names_out(['Age', 'Years at Company']))\n",
    "\n",
    "# Add the polynomial features to the dataset\n",
    "X = pd.concat([X, poly_features_df], axis=1)\n",
    "\n",
    "# Now let's proceed with the rest of the steps (Encoding, Splitting, etc.)\n",
    "\n",
    "# Step 1: Encode categorical variables (binary with LabelEncoder, multi-category with OneHotEncoder)\n",
    "label_encoder = LabelEncoder()\n",
    "X['Gender'] = label_encoder.fit_transform(X['Gender'])\n",
    "\n",
    "# One-hot encode multi-category variables\n",
    "categorical_columns = ['Education Level', 'Department', 'Job Title', 'Organization Level', 'Career Growth Satisfaction', 'Manager Feedback Effectiveness', 'Team Collaboration Score']\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Step 2: Apply SMOTE\n",
    "y = merged_data['Attrition']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train Gradient Boosting model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Train the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "y_pred_proba = gb_model.predict_proba(X_test)\n",
    "\n",
    "# Extract the probability for the 'Attrition' class (class 1)\n",
    "attrition_probabilities = y_pred_proba[:, 1]\n",
    "\n",
    "# Display the predicted probabilities along with the actual values\n",
    "results = pd.DataFrame({\n",
    "    'Actual Attrition': y_test,\n",
    "    'Predicted Attrition Probability': attrition_probabilities\n",
    "})\n",
    "\n",
    "# Show the first few rows\n",
    "print(results.head())\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "print(\"Gradient Boosting Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nGradient Boosting Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a112c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Confusion Matrix:\n",
      "[[1218   30]\n",
      " [ 104   13]]\n",
      "\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      1248\n",
      "           1       0.30      0.11      0.16       117\n",
      "\n",
      "    accuracy                           0.90      1365\n",
      "   macro avg       0.61      0.54      0.56      1365\n",
      "weighted avg       0.87      0.90      0.88      1365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Train Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Gradient Boosting Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_gb))\n",
    "\n",
    "print(\"\\nGradient Boosting Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2339042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from RandomizedSearchCV:\n",
      "{'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 6, 'learning_rate': 0.1}\n",
      "Best Gradient Boosting Confusion Matrix:\n",
      "[[1248    0]\n",
      " [  32   85]]\n",
      "\n",
      "Best Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      1248\n",
      "           1       1.00      0.73      0.84       117\n",
      "\n",
      "    accuracy                           0.98      1365\n",
      "   macro avg       0.99      0.86      0.91      1365\n",
      "weighted avg       0.98      0.98      0.97      1365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Randomized Search with cross-validation\n",
    "random_search = RandomizedSearchCV(gb_model, param_grid, n_iter=10, cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Best parameters and model\n",
    "print(\"Best Parameters from RandomizedSearchCV:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "# Train the best model\n",
    "best_gb_model = random_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_best_gb = best_gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "print(\"Best Gradient Boosting Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_best_gb))\n",
    "\n",
    "print(\"\\nBest Gradient Boosting Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d12e476e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual Attrition  Predicted Attrition Probability\n",
      "101                  0                         0.100729\n",
      "2666                 0                         0.032608\n",
      "3838                 0                         0.071850\n",
      "2388                 0                         0.037668\n",
      "5438                 0                         0.141044\n",
      "\n",
      "Predicted probabilities of resignation for active employees:\n",
      "      Actual Attrition  Predicted Attrition Probability\n",
      "101                  0                         0.100729\n",
      "2666                 0                         0.032608\n",
      "3838                 0                         0.071850\n",
      "2388                 0                         0.037668\n",
      "5438                 0                         0.141044\n",
      "...                ...                              ...\n",
      "1554                 0                         0.035213\n",
      "6490                 0                         0.114124\n",
      "3910                 0                         0.094654\n",
      "6075                 0                         0.040505\n",
      "1357                 0                         0.088246\n",
      "\n",
      "[1248 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Train Gradient Boosting model on the training data (X_train, y_train)\n",
    "gb_model = GradientBoostingClassifier(n_estimators=200, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Now, predict probabilities for the test set\n",
    "y_pred_proba = gb_model.predict_proba(X_test)\n",
    "\n",
    "# Extract the probability for the 'Attrition' class (class 1)\n",
    "attrition_probabilities = y_pred_proba[:, 1]\n",
    "\n",
    "# Combine the results into a DataFrame for better readability\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual Attrition': y_test,\n",
    "    'Predicted Attrition Probability': attrition_probabilities\n",
    "})\n",
    "\n",
    "# Display the top rows to see the results\n",
    "print(results_df.head())\n",
    "\n",
    "# Optionally, filter for active employees (assuming attrition '0' means active)\n",
    "active_employees_df = results_df[results_df['Actual Attrition'] == 0]\n",
    "\n",
    "# Show the probabilities of resignation for active employees\n",
    "print(\"\\nPredicted probabilities of resignation for active employees:\")\n",
    "print(active_employees_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a085785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution of predicted resignation probabilities for active employees\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(active_employees_df['Predicted Attrition Probability'], bins=30, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Predicted Resignation Probabilities for Active Employees')\n",
    "plt.xlabel('Predicted Resignation Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f163fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "High risk employees:\n",
      "      Actual Attrition  Predicted Attrition Probability  High Risk\n",
      "2185                 0                         0.556907       True\n",
      "2184                 0                         0.668373       True\n",
      "5514                 0                         0.588147       True\n"
     ]
    }
   ],
   "source": [
    "# Set a threshold for high resignation risk\n",
    "threshold = 0.5\n",
    "\n",
    "# Classify employees with a probability greater than the threshold as \"high risk\"\n",
    "active_employees_df['High Risk'] = active_employees_df['Predicted Attrition Probability'] > threshold\n",
    "\n",
    "# Show the high-risk employees\n",
    "high_risk_employees = active_employees_df[active_employees_df['High Risk'] == True]\n",
    "print(\"\\nHigh risk employees:\")\n",
    "print(high_risk_employees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36530694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'X_test' is the features for active employees\n",
    "# 'y_pred_proba' contains predicted probabilities (from your Gradient Boosting model)\n",
    "\n",
    "# Add the probabilities and high risk status to the DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Example of high-risk threshold\n",
    "high_risk_threshold = 0.5\n",
    "\n",
    "# Add predicted probabilities to the DataFrame\n",
    "all_employees_predictions = X_test.copy()  # Use the features DataFrame or create a new one\n",
    "\n",
    "# Add predicted probabilities to the DataFrame\n",
    "all_employees_predictions['Predicted Attrition Probability'] = y_pred_proba[:, 1]\n",
    "\n",
    "# Add a high-risk column based on the threshold\n",
    "all_employees_predictions['High Risk'] = all_employees_predictions['Predicted Attrition Probability'] >= high_risk_threshold\n",
    "\n",
    "# Optionally, add Actual Attrition if it's available in your dataset\n",
    "# all_employees_predictions['Actual Attrition'] = y_test\n",
    "\n",
    "# Save to CSV\n",
    "all_employees_predictions.to_csv('active_employees_with_resignation_probabilities.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e32cefe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual Attrition  Predicted Attrition Probability  High Risk  \\\n",
      "101                  0                         0.100729      False   \n",
      "2666                 0                         0.032608      False   \n",
      "3838                 0                         0.071850      False   \n",
      "2388                 0                         0.037668      False   \n",
      "5438                 0                         0.141044      False   \n",
      "\n",
      "      Employee ID  \n",
      "101           NaN  \n",
      "2666          NaN  \n",
      "3838          NaN  \n",
      "2388          NaN  \n",
      "5438          NaN  \n"
     ]
    }
   ],
   "source": [
    "# Define a threshold for high risk (e.g., 0.5)\n",
    "high_risk_threshold = 0.5\n",
    "\n",
    "# Add a High Risk column: employees with a probability >= threshold are considered high risk\n",
    "active_employees_df['High Risk'] = active_employees_df['Predicted Attrition Probability'] >= high_risk_threshold\n",
    "\n",
    "# Include Employee ID from the 'employee' dataset\n",
    "active_employees_df['Employee ID'] = employee.loc[employee['Employee ID'].isin(active_employees_df.index), 'Employee ID']\n",
    "\n",
    "# Save to CSV\n",
    "active_employees_df[['Employee ID', 'Predicted Attrition Probability', 'High Risk']].to_csv('active_employees_resignation_probabilities.csv', index=False)\n",
    "\n",
    "# Display the saved file for review\n",
    "print(active_employees_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5d88f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Employee ID  Actual Attrition  Predicted Attrition Probability\n",
      "0         1001               NaN                              NaN\n",
      "1         1002               0.0                         0.072004\n",
      "2         1003               NaN                              NaN\n",
      "3         1004               NaN                              NaN\n",
      "4         1005               0.0                         0.067098\n"
     ]
    }
   ],
   "source": [
    "# Filter the employees where Current Employment Status is 'Active'\n",
    "active_employees = employee[employee['Current Employment Status'] == 'Active']\n",
    "\n",
    "# Merge the active employees with their predicted attrition probabilities\n",
    "# Assuming `results_df` contains the predicted probabilities and is indexed by Employee ID\n",
    "# Ensure Employee ID is a part of the results_df for merging\n",
    "active_employees_with_probabilities = active_employees[['Employee ID']].merge(results_df, left_on='Employee ID', right_index=True, how='left')\n",
    "\n",
    "# Save to CSV, including the Employee ID and predicted attrition probability\n",
    "active_employees_with_probabilities.to_csv('active_employe_with_resignation_probabilities.csv', index=False)\n",
    "\n",
    "# Display the top rows to confirm the results\n",
    "print(active_employees_with_probabilities.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "916a2e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Employee ID  Predicted Attrition Probability\n",
      "0         1001                              NaN\n",
      "1         1002                         0.072004\n",
      "2         1003                              NaN\n",
      "3         1004                              NaN\n",
      "4         1005                         0.067098\n"
     ]
    }
   ],
   "source": [
    "# Ensure the 'Employee ID' is included in the results_df\n",
    "results_df['Employee ID'] = y_test.index  # Assuming y_test index corresponds to Employee IDs\n",
    "\n",
    "# Filter the employees where Current Employment Status is 'Active'\n",
    "active_employees = employee[employee['Current Employment Status'] == 'Active']\n",
    "\n",
    "# Merge the active employees with the predicted attrition probabilities\n",
    "# Merge on 'Employee ID' to ensure we capture the predicted probabilities for each active employee\n",
    "active_employees_with_probabilities = active_employees[['Employee ID']].merge(\n",
    "    results_df[['Employee ID', 'Predicted Attrition Probability']], \n",
    "    on='Employee ID', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "active_employees_with_probabilities.to_csv('active_employees_with_resignation_probabilities.csv', index=False)\n",
    "\n",
    "# Display the top rows to confirm the results\n",
    "print(active_employees_with_probabilities.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cd3d0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Employee ID  Actual Attrition  Predicted Attrition Probability\n",
      "6300         6300                 1                         0.957176\n",
      "6365         6365                 1                         0.846451\n",
      "5931         5931                 1                         0.785732\n",
      "4625         4625                 1                         0.783110\n",
      "5048         5048                 1                         0.761982\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a way to track the original indices of the test set\n",
    "results_df = pd.DataFrame({\n",
    "    'Employee ID': X_test.index,  # Use the original indices directly\n",
    "    'Actual Attrition': y_test,\n",
    "    'Predicted Attrition Probability': gb_model.predict_proba(X_test)[:, 1]\n",
    "})\n",
    "\n",
    "# Sort by Predicted Attrition Probability in descending order\n",
    "results_df = results_df.sort_values('Predicted Attrition Probability', ascending=False)\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('employee_resignation_probabilities.csv', index=False)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d215fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Active Employees: 1561\n",
      "Number of Employees in Current Dataset: 1800\n"
     ]
    }
   ],
   "source": [
    "# Filter active employees\n",
    "active_employees = employee[employee['Current Employment Status'] == 'Active']\n",
    "\n",
    "# Check the total number of active employees\n",
    "total_active_employees = len(active_employees)\n",
    "\n",
    "# Compare with the number of employees in your current dataset\n",
    "print(f\"Total Active Employees: {total_active_employees}\")\n",
    "print(f\"Number of Employees in Current Dataset: {len(employee)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3fb17418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Employee ID  Predicted Attrition Probability\n",
      "1085         2086                         0.957176\n",
      "1087         2088                         0.846451\n",
      "170          1171                         0.785732\n",
      "1155         2156                         0.783110\n",
      "1323         2324                         0.761982\n"
     ]
    }
   ],
   "source": [
    "# Filter active employees\n",
    "active_employees = employee[employee['Current Employment Status'] == 'Active']\n",
    "\n",
    "# Predict probabilities for all active employees\n",
    "active_employee_probas = gb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Create a DataFrame with Employee ID and Predicted Attrition Probability\n",
    "results_df = pd.DataFrame({\n",
    "    'Employee ID': active_employees['Employee ID'][:len(active_employee_probas)],\n",
    "    'Predicted Attrition Probability': active_employee_probas\n",
    "})\n",
    "\n",
    "# Sort by Predicted Attrition Probability in descending order\n",
    "results_df = results_df.sort_values('Predicted Attrition Probability', ascending=False)\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('1active_employee_resignation_probabilities.csv', index=False)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d85991c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'No'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 167\u001b[0m\n\u001b[0;32m    164\u001b[0m employee, resigned_table, resignation_reason, exit_interview_survey, employee_feedback_survey \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# Run the analysis\u001b[39;00m\n\u001b[1;32m--> 167\u001b[0m analyze_resignations(employee, resigned_table, resignation_reason, \n\u001b[0;32m    168\u001b[0m                    exit_interview_survey, employee_feedback_survey)\n",
      "Cell \u001b[1;32mIn[2], line 136\u001b[0m, in \u001b[0;36manalyze_resignations\u001b[1;34m(employee, resigned_table, resignation_reason, exit_interview_survey, employee_feedback_survey)\u001b[0m\n\u001b[0;32m    133\u001b[0m full_data \u001b[38;5;241m=\u001b[39m add_resignation_indicator(full_data)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Calculate correlations\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m correlations \u001b[38;5;241m=\u001b[39m calculate_correlations(full_data)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Plot correlations\u001b[39;00m\n\u001b[0;32m    139\u001b[0m plot_correlations(correlations)\n",
      "Cell \u001b[1;32mIn[2], line 76\u001b[0m, in \u001b[0;36mcalculate_correlations\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     64\u001b[0m correlation_cols \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBase Salary ($)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimes Promoted\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHas_Resigned\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     73\u001b[0m ]\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Calculate correlations\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m correlations \u001b[38;5;241m=\u001b[39m df[correlation_cols]\u001b[38;5;241m.\u001b[39mcorr()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHas_Resigned\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msort_values()\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m correlations\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11049\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  11047\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  11048\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 11049\u001b[0m mat \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto_numpy(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m, na_value\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m  11051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  11052\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mas_array(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, na_value\u001b[38;5;241m=\u001b[39mna_value)\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interleave(dtype\u001b[38;5;241m=\u001b[39mdtype, na_value\u001b[38;5;241m=\u001b[39mna_value)\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1753\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1753\u001b[0m     result[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'No'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# First load the data\n",
    "def load_data():\n",
    "    try:\n",
    "        employee = pd.read_csv('employee.csv')\n",
    "        resigned_table = pd.read_csv('resigned_table.csv')\n",
    "        resignation_reason = pd.read_csv('resignation_reason.csv')\n",
    "        exit_interview_survey = pd.read_csv('exit_interview_survey.csv')\n",
    "        employee_feedback_survey = pd.read_csv('employee_feedback_survey.csv')\n",
    "        \n",
    "        return employee, resigned_table, resignation_reason, exit_interview_survey, employee_feedback_survey\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading files: {e}\")\n",
    "        return None\n",
    "\n",
    "def prepare_data(employee, resigned_table, resignation_reason, exit_interview_survey, employee_feedback_survey):\n",
    "    # Merge resigned_table with resignation_reason\n",
    "    resigned_data = pd.merge(\n",
    "        resigned_table,\n",
    "        resignation_reason,\n",
    "        on='Resignation Reason ID',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Merge with employee data\n",
    "    full_data = pd.merge(\n",
    "        employee,\n",
    "        resigned_data,\n",
    "        on='Employee ID',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Merge with exit interview data\n",
    "    full_data = pd.merge(\n",
    "        full_data,\n",
    "        exit_interview_survey,\n",
    "        on='Employee ID',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Get the most recent feedback for each employee\n",
    "    latest_feedback = employee_feedback_survey.sort_values('Year').groupby('Employee ID').last().reset_index()\n",
    "    \n",
    "    # Merge with employee feedback\n",
    "    full_data = pd.merge(\n",
    "        full_data,\n",
    "        latest_feedback,\n",
    "        on='Employee ID',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    return full_data\n",
    "\n",
    "def add_resignation_indicator(df):\n",
    "    df['Has_Resigned'] = df['Resigned Date'].notna().astype(int)\n",
    "    return df\n",
    "\n",
    "def calculate_correlations(df):\n",
    "    # Select numerical columns and 'Has_Resigned'\n",
    "    correlation_cols = [\n",
    "        'Base Salary ($)',\n",
    "        'Times Promoted',\n",
    "        'Years at Company',\n",
    "        'Work Environment Satisfaction Score',\n",
    "        'Team Collaboration Score',\n",
    "        'Career Growth Satisfaction',\n",
    "        'Overall Performance Rating',\n",
    "        'Has_Resigned'\n",
    "    ]\n",
    "    \n",
    "    # Calculate correlations\n",
    "    correlations = df[correlation_cols].corr()['Has_Resigned'].sort_values()\n",
    "    \n",
    "    return correlations\n",
    "\n",
    "def plot_correlations(correlations):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x=correlations.values[:-1], y=correlations.index[:-1])\n",
    "    plt.title('Factors Correlated with Employee Resignation')\n",
    "    plt.xlabel('Correlation Coefficient')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_specific_factors(df):\n",
    "    # Analyze salary impact\n",
    "    salary_bins = pd.qcut(df['Base Salary ($)'], q=5)\n",
    "    salary_analysis = df.groupby(salary_bins)['Has_Resigned'].agg(['mean', 'count'])\n",
    "    \n",
    "    # Analyze tenure impact\n",
    "    tenure_bins = pd.qcut(df['Years at Company'], q=5)\n",
    "    tenure_analysis = df.groupby(tenure_bins)['Has_Resigned'].agg(['mean', 'count'])\n",
    "    \n",
    "    print(\"\\nResignation Rate by Salary Quintiles:\")\n",
    "    print(salary_analysis)\n",
    "    \n",
    "    print(\"\\nResignation Rate by Tenure Quintiles:\")\n",
    "    print(tenure_analysis)\n",
    "\n",
    "def create_detailed_visualizations(df):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "    \n",
    "    # Salary vs Resignation\n",
    "    sns.boxplot(x='Has_Resigned', y='Base Salary ($)', data=df, ax=axes[0,0])\n",
    "    axes[0,0].set_title('Salary Distribution by Resignation Status')\n",
    "    \n",
    "    # Years at Company vs Resignation\n",
    "    sns.boxplot(x='Has_Resigned', y='Years at Company', data=df, ax=axes[0,1])\n",
    "    axes[0,1].set_title('Tenure Distribution by Resignation Status')\n",
    "    \n",
    "    # Department vs Resignation\n",
    "    dept_resign = df.groupby('Department')['Has_Resigned'].mean().sort_values()\n",
    "    dept_resign.plot(kind='bar', ax=axes[1,0])\n",
    "    axes[1,0].set_title('Resignation Rate by Department')\n",
    "    \n",
    "    # Performance Rating vs Resignation\n",
    "    perf_resign = df.groupby('Overall Performance Rating')['Has_Resigned'].mean().sort_values()\n",
    "    perf_resign.plot(kind='bar', ax=axes[1,1])\n",
    "    axes[1,1].set_title('Resignation Rate by Performance Rating')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_resignations(employee, resigned_table, resignation_reason, exit_interview_survey, employee_feedback_survey):\n",
    "    # Prepare data\n",
    "    full_data = prepare_data(employee, resigned_table, resignation_reason, \n",
    "                           exit_interview_survey, employee_feedback_survey)\n",
    "    \n",
    "    # Add resignation indicator\n",
    "    full_data = add_resignation_indicator(full_data)\n",
    "    \n",
    "    # Calculate correlations\n",
    "    correlations = calculate_correlations(full_data)\n",
    "    \n",
    "    # Plot correlations\n",
    "    plot_correlations(correlations)\n",
    "    \n",
    "    # Print correlations\n",
    "    print(\"\\nCorrelations with Resignation:\")\n",
    "    print(correlations)\n",
    "    \n",
    "    # Analyze categorical variables\n",
    "    categorical_analysis = pd.DataFrame({\n",
    "        'Resignation_Rate': full_data.groupby('Department')['Has_Resigned'].mean(),\n",
    "        'Count': full_data.groupby('Department')['Has_Resigned'].count()\n",
    "    }).sort_values('Resignation_Rate', ascending=False)\n",
    "    \n",
    "    print(\"\\nResignation Rates by Department:\")\n",
    "    print(categorical_analysis)\n",
    "    \n",
    "    # Additional analyses\n",
    "    analyze_specific_factors(full_data)\n",
    "    create_detailed_visualizations(full_data)\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the data first\n",
    "    data = load_data()\n",
    "    \n",
    "    if data is not None:\n",
    "        employee, resigned_table, resignation_reason, exit_interview_survey, employee_feedback_survey = data\n",
    "        \n",
    "        # Run the analysis\n",
    "        analyze_resignations(employee, resigned_table, resignation_reason, \n",
    "                           exit_interview_survey, employee_feedback_survey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba20347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
