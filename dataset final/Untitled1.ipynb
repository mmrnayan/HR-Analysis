{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd18ccc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation complete. Ready for training.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load datasets\n",
    "employee = pd.read_csv('employee.csv')\n",
    "resigned_table = pd.read_csv('resigned_table.csv')\n",
    "resignation_reason = pd.read_csv('resignation_reason.csv')\n",
    "exit_interview_survey = pd.read_csv('exit_interview_survey.csv')\n",
    "employee_feedback_survey = pd.read_csv('employee_feedback_survey.csv')\n",
    "\n",
    "# Merge relevant datasets\n",
    "# Merging resigned table with resignation reason\n",
    "resigned_data = pd.merge(resigned_table, resignation_reason, on='Resignation Reason ID', how='left')\n",
    "\n",
    "# Merging resigned data with exit interview survey\n",
    "resigned_data = pd.merge(resigned_data, exit_interview_survey, on='Employee ID', how='left')\n",
    "\n",
    "# Filtering out only active employees\n",
    "active_employees = employee[employee['Current Employment Status'] == 'Active']\n",
    "\n",
    "# Creating a unified dataset for analysis\n",
    "attrition_data = pd.merge(employee, resigned_data, on='Employee ID', how='left')\n",
    "\n",
    "# Fill missing values for active employees\n",
    "attrition_data.fillna({'Resigned Type': 'Not Resigned', 'Resignation Reason': 'None'}, inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_columns = ['Gender', 'Education Level', 'Department', 'Employment Type', 'Resigned Type']\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "for col in categorical_columns:\n",
    "    attrition_data[col] = encoder.fit_transform(attrition_data[col])\n",
    "\n",
    "# Feature selection\n",
    "features = ['Gender', 'Education Level', 'Department', 'Employment Type', 'Base Salary ($)', \n",
    "            'Times Promoted', 'Years at Company', 'Work Environment Feedback', \n",
    "            'Management/Team Experience Score']\n",
    "target = 'Current Employment Status'\n",
    "\n",
    "# Preparing data for the model\n",
    "X = attrition_data[features]\n",
    "y = attrition_data[target].apply(lambda x: 1 if x != 'Active' else 0)  # 1 for Resigned, 0 for Active\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data preparation complete. Ready for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a4b2809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns encoded successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Identify columns with non-numeric data in X_train and X_test\n",
    "categorical_columns = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Apply Label Encoding for simplicity (One-Hot Encoding is another option)\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    X_train[col] = le.fit_transform(X_train[col])\n",
    "    X_test[col] = le.transform(X_test[col])  # Ensure consistency with training data\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(\"Categorical columns encoded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdfaae21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender                                int32\n",
      "Education Level                       int32\n",
      "Department                            int32\n",
      "Employment Type                       int32\n",
      "Base Salary ($)                     float64\n",
      "Times Promoted                        int64\n",
      "Years at Company                      int64\n",
      "Work Environment Feedback             int32\n",
      "Management/Team Experience Score    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c70d650c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable encoded successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "print(\"Target variable encoded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b703f69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in X_train:\n",
      "Gender                                 0\n",
      "Education Level                        0\n",
      "Department                             0\n",
      "Employment Type                        0\n",
      "Base Salary ($)                        0\n",
      "Times Promoted                         0\n",
      "Years at Company                       0\n",
      "Work Environment Feedback              0\n",
      "Management/Team Experience Score    1248\n",
      "dtype: int64\n",
      "\n",
      "Missing values in y_train:\n",
      "0\n",
      "\n",
      "Missing values in X_train after handling:\n",
      "Gender                              0\n",
      "Education Level                     0\n",
      "Department                          0\n",
      "Employment Type                     0\n",
      "Base Salary ($)                     0\n",
      "Times Promoted                      0\n",
      "Years at Company                    0\n",
      "Work Environment Feedback           0\n",
      "Management/Team Experience Score    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3356\\184532985.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train['Management/Team Experience Score'].fillna(X_train['Management/Team Experience Score'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check for missing values in X_train\n",
    "print(\"Missing values in X_train:\")\n",
    "print(X_train.isnull().sum())\n",
    "\n",
    "# Convert y_train to a pandas Series to check for nulls\n",
    "y_train_series = pd.Series(y_train)\n",
    "print(\"\\nMissing values in y_train:\")\n",
    "print(y_train_series.isnull().sum())\n",
    "\n",
    "# Handle missing values in X_train (example: fill with median or drop)\n",
    "X_train['Management/Team Experience Score'].fillna(X_train['Management/Team Experience Score'].median(), inplace=True)\n",
    "print(\"\\nMissing values in X_train after handling:\")\n",
    "print(X_train.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b25c9819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1440, 9)\n",
      "y_train shape: (1440,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "# If y_train has the wrong shape, reshape it\n",
    "y_train = y_train.ravel()  # Flatten to (n_samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6a1ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07610bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Parameters: {'subsample': 0.8, 'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_depth': 5, 'learning_rate': 0.2}\n",
      "Best Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'subsample': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "gbm = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Randomized Search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=gbm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,  # Number of parameter settings sampled\n",
    "    scoring='accuracy',  # Metric to optimize\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and accuracy\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Accuracy:\", random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "977dc212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values in X_test: 313\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check for missing values in the NumPy array\n",
    "missing_values = np.isnan(X_test).sum()\n",
    "print(f\"Total missing values in X_test: {missing_values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f06dc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
